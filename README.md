# Project_MNIST
Comparison on of Decision Tree Classifier, K-Neighbors Classifier and Artificial Neural Network 

# üìä Algorithms Compared

1Ô∏è‚É£ Decision Tree Classifier

A tree-based model that splits data based on feature conditions.
used one classifier with some pruning features, other without any
Evaluated with and without pruning to analyze overfitting.

2Ô∏è‚É£ K-Nearest Neighbors (KNN)

A non-parametric algorithm that classifies based on the majority vote of nearest neighbors.
used 5 and 10 for n_neighbors
Different values of k were tested to optimize performance.

3Ô∏è‚É£ Artificial Neural Network (ANN)

Implemented using TensorFlow/Keras.

Tested different architectures, activation functions, and optimizers.



# Observations & Findings

Decision Trees are fast and interpretable but prone to overfitting.

KNN performs well with optimized k-values but is computationally expensive for large datasets.

ANN achieves higher accuracy but requires more training time and tuning.
